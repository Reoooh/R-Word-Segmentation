# Ruby Word Segmentation

A simple Ruby project for Chinese &amp; Japanese word segmentation

## Installation

```bash
git clone https://github.com/Reoooh/sRWS.git
```

Please make sure the Ruby environment is installed.

## Function & Description

All methods of this word segmentation project are based on the String matching theory [dictionary scheme].

This project can be applied to Chinese and Japanese word segmentation.

### CWS [Chinese Word Segmentation]

**Segmentation algorithm:**
>forward maximum matching method

>backward maximum matching method

>bidirectional maximum matching method 

**Dictionary source:**
>The dictionary for Chinese Word Segmentation comes from the open source project [**HanLP**](https://github.com/hankcs/HanLP).

### JWS [Japanese Word Segmentation]

**Segmentation algorithm:**
>forward maximum matching method

**Dictionary source:**
>The dictionary for Japanese Word Segmentation is generated by the kernel program. The final dictionary uses most of the variants of verbs and adjectives. Therefore, the number of words in the final dictionary exceeds more than 20 times of the original dictionary.

>*WARNING: the original dictionary comes from the book "红宝书10000日语单词随身带". The electronic version is manually generated by me. Please make sure you hold this book in any form if you need to use the original dictionary.*

## Start

### CWS

You can start like this.

```bash
>>ruby Connecter.rb "中文分词测试"
FORWARD: ["中文", "分词", "测试"]
BACKWARD: ["中文", "分词", "测试"]
BIDIRECTIONAL: ["中文", "分词", "测试"]
```

And test the time spent on word segmentation processing.

```bash
>>ruby Connectertest.rb "中文分词测试"
FORWARD: ["中文", "分词", "测试"]
Rehearsal ----------------------------------------------
search:      3.906000   0.047000   3.953000 (  4.091308)
------------------------------------- total: 3.953000sec

                 user     system      total        real
search:      4.266000   0.047000   4.313000 (  4.481178)
BACKWARD: ["中文", "分词", "测试"]
Rehearsal ----------------------------------------------
search:      2.938000   0.047000   2.985000 (  3.071883)
------------------------------------- total: 2.985000sec

                 user     system      total        real
search:      2.890000   0.047000   2.937000 (  3.084197)
BIDIRECTIONAL: ["中文", "分词", "测试"]
Rehearsal ----------------------------------------------
search:      6.938000   0.125000   7.063000 (  7.202268)
------------------------------------- total: 7.063000sec

                 user     system      total        real
search:      7.672000   0.094000   7.766000 (  7.912471)
```

### JWS

```bash
>>ruby Connecter.rb "日本語言葉区分するテスト"
FORWARD: ["日本語", "言葉", "区分する", "テスト"]
```

```bash
>>ruby Connectertest.rb "日本語言葉区分するテスト"
["日本語", "言葉", "区分する", "テスト"]
Rehearsal ----------------------------------------------
search:     31.531000   0.796000  32.327000 ( 32.399480)
------------------------------------ total: 32.327000sec

                 user     system      total        real
search:     35.328000   0.813000  36.141000 ( 36.839869)
```

Actually, the correct Japanese sentences is as follows:

```bash
>>ruby Connecter.rb "日本言葉語区分するテスト"
FORWARD: ["日本語", "単", "語", "分", "割", "テスト"]
```

```bash
>>ruby Connectertest.rb "日本語単語分割テスト"
["日本語", "単", "語", "分", "割", "テスト"]
Rehearsal ----------------------------------------------
search:     32.344000   0.563000  32.907000 ( 32.941230)
------------------------------------ total: 32.907000sec

                 user     system      total        real
search:     31.969000   0.984000  32.953000 ( 32.970740)
```

Hence you can find out the flaws in this word segmentation processing project: program cannot recognize words that not included in the dictionary.

## License

*GNU General Public License v3.0*